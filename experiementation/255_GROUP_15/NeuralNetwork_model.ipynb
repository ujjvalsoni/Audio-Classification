{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to add X and Y\n",
    "# Train Test Split : Xtrain, Xtest, Ytrain, Ytest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uttara/Documents/Anaconda/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, TensorFlow!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# hello = tf.constant('Hello, TensorFlow!')\n",
    "# sess = tf.Session()\n",
    "# print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_epochs = 2640\n",
    "dim = len_feature\n",
    "classnum = 50\n",
    "hidden1 = 300 \n",
    "hidden2 = 300\n",
    "# standard deviation\n",
    "sd = 1 / np.sqrt(dim) \n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert 2d into 1d and define placeholder for classes, currently blank\n",
    "# TF Graph input\n",
    "# placeholders for features and class labels, which tensor flow will fill with the data at runtime.\n",
    "X = tf.placeholder(tf.float32,[None,dim]) \n",
    "Y = tf.placeholder(tf.float32,[None,classnum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Weight and bias\n",
    "# TANH function in the first hidden layer\n",
    "W1 = tf.Variable(tf.random_normal([dim,hidden1], mean = 0, stddev=sd))\n",
    "b1 = tf.Variable(tf.random_normal([hidden1], mean = 0, stddev=sd))\n",
    "hf1 = tf.nn.tanh(tf.matmul(X,W1) + b1)\n",
    "\n",
    "# Sigmoid function in the second hidden layer\n",
    "W2 = tf.Variable(tf.random_normal([hidden1,hidden2], mean = 0, stddev=sd))\n",
    "b2 = tf.Variable(tf.random_normal([hidden2], mean = 0, stddev=sd))\n",
    "hf2 = tf.nn.sigmoid(tf.matmul(hf1,W2) + b2)\n",
    "\n",
    "# Softmax function in output layer\n",
    "W = tf.Variable(tf.random_normal([hidden2,classnum], mean = 0, stddev=sd))\n",
    "b = tf.Variable(tf.random_normal([classnum], mean = 0, stddev=sd))\n",
    "finalY = tf.nn.softmax(tf.matmul(hf2,W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Summary Operations\n",
    "wHisto=tf.histogram_summary(\"Weights\",W)\n",
    "bHisto=tf.histogram_summary(\"Biases\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Minimise error - Cross Entropy Function\n",
    "cost_function = -tf.reduce_sum(Y * tf.log(finalY))\n",
    "tf.scalar_summary(\"Cost Function\", cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Optimisation Function - Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialise all variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merge all summaries into single operator\n",
    "mergedSummary=tf.merge_all_summaries()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining and initializing variables for accuracy calculation \n",
    "correct_prediction = tf.equal(tf.argmax(finalY,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "y_true, y_pred = None, None\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(training_epochs):            \n",
    "        _,cost = sess.run([optimizer,cost_function],feed_dict={X;Xtrain,Y:Ytrain})\n",
    "        cost_history = np.append(cost_history,cost)\n",
    "    \n",
    "    y_pred = sess.run(tf.argmax(finalY,1),feed_dict={X: Xtest})\n",
    "    y_true = sess.run(tf.argmax(Ytest,1))\n",
    "    print('Test accuracy: ',round(session.run(accuracy, feed_dict={X: Xtest, Y: Ytest}) , 3))\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(cost_history)\n",
    "plt.axis([0,training_epochs,0,np.max(cost_history)])\n",
    "plt.show()\n",
    "\n",
    "p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "print \"F-Score:\", round(f,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
